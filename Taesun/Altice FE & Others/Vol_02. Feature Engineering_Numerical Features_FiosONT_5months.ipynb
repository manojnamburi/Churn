{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engineer Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Custom Transformers for Numerical Features\n",
    "**Feature engineering for numerical features** consists of:\n",
    "- sklearn-Based Transformers\n",
    "    - `StandardScaler_DF`\n",
    "    - `RobusScaler_DF`    \n",
    "    - `MinMaxScaler_DF`\n",
    "    - `MaxAbsScaler_DF`\n",
    "    - `Normalizer_DF`\n",
    "    - `PowerTransformer_DF`\n",
    "    - `Binarizer_DT`\n",
    "    - `QuantileTransformer_DF`     \n",
    "    - `KBinsDiscretizer_DF`\n",
    "    \n",
    "- numpy-Based Transformers\n",
    "    - `Log1pTransformer`\n",
    "    - `SqrtTransformer`\n",
    "    - `ReciprocalTransformer`\n",
    "\n",
    "- Utility Transformers\n",
    "    - `FeatureUnion_DF`\n",
    "        - Concatenate all returns of Custom Transformers in dataframe (df).\n",
    "    - `UniversalTransformer`\n",
    "        - Transform a given df with a general function a user provides.\n",
    "    - `PassTransformer`\n",
    "        - Pass a given df to next without any transformation.\n",
    "    - `FeatureSelector`\n",
    "        - Select given features from a df.\n",
    "    - `FeatureSelector_NUM`\n",
    "        - Select NUMERICAL features from a df.\n",
    "    - `FeatureSelector_CAT`\n",
    "        - Select CATEGORICAL features from a df.\n",
    "  \n",
    "- **Note**: \n",
    "    - Data will have ***'pandas dataframe'*** format before/after transformation.\n",
    "    - ***sklearn/numpy-based transfomers*** have the same functionalities in dataframe as their alternatives in sklearn/numpy.\n",
    "\n",
    "- References: \n",
    "    - sklearn Preprocessing: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "    - sklear Pipeline: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "    - pandas-pipelines-custom-transformers: https://github.com/jem1031/pandas-pipelines-custom-transformers\n",
    "    - In-house Code: 'data_procesing_for_modeling.py' \n",
    "    - Featuretools: https://docs.featuretools.com/#\n",
    "    - Feature Engine: https://pypi.org/project/feature-engine/\n",
    "    - Category Encoders: http://contrib.scikit-learn.org/categorical-encoding/    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-Processed TRAIN/TEST Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 0. Import Required Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "### Import Customer Transformers\n",
    "import PreProcessing_Custom_Transformers_v2 as PP\n",
    "import FeatureEngineering_Custom_Transformers as FE\n",
    "import FeatureCreation_Custom_Transformers as FC\n",
    "\n",
    "# Remove DataConversionWarning\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "TRAIN vs TEST Datasets\n",
      "**************************************************\n",
      "The Shape of TRAIN Data: (102451, 777)\n",
      "The Shape of TEST Data:  (100858, 777)\n",
      "\n",
      "**************************************************\n",
      "Overall Churn Rate\n",
      "**************************************************\n",
      "TRAIN:  0.0367\n",
      "TEST:   0.0405 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use Pre-Processed Data as TRAIN and TEST\n",
    "df_train = pd.read_pickle('data_new/Vol_df_train_FiosONT_PP_5months.pkl')\n",
    "df_test  = pd.read_pickle('data_new/Vol_df_test_FiosONT_PP_5months.pkl')\n",
    "\n",
    "# TRAIN\n",
    "train_X = df_train.drop('status', axis=1).copy()\n",
    "train_y = df_train['status']\n",
    "\n",
    "# TEST\n",
    "test_X  = df_test.drop('status', axis=1).copy()\n",
    "test_y  = df_test['status']\n",
    "\n",
    "# Sample Size\n",
    "print('*'*50 + '\\nTRAIN vs TEST Datasets\\n' + '*'*50)\n",
    "# print('Competitive Area: ', df_train.competitive_area.unique())\n",
    "print('The Shape of TRAIN Data: ' + str(df_train.shape))\n",
    "print('The Shape of TEST Data:  ' + str(df_test.shape))\n",
    "\n",
    "## Churn Rate by Sample Type\n",
    "print('\\n' + '*'*50 + '\\nOverall Churn Rate\\n' + '*'*50)\n",
    "print('TRAIN: ', df_train.status.value_counts(normalize=True)[1].round(4))\n",
    "print('TEST:  ', df_test.status.value_counts(normalize=True)[1].round(4), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/Use a Meta Custom Transfomer for Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************************\n",
      "Before vs After Feature Engineering (FE)\n",
      "**************************************************\n",
      "TRAIN: Before FE:(102451, 776)\n",
      "TRAIN: After FE: (102451, 4992)\n",
      "TEST:  After FE: (100858, 4992)\n",
      "CPU times: user 1min 57s, sys: 33.6 s, total: 2min 31s\n",
      "Wall time: 49.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# (1) Make a Pipeline in Parallel/Sequence and Instantiate \n",
    "# Custom Transformers in Parallel for NUMERICAL Features\n",
    "Pipe_FU          =  FE.FeatureUnion_DF([\n",
    "                    ('Original', FE.PassTransformer(prefix='Original')),\n",
    "                    ('Standard', FE.StandardScaler_DF(prefix='Standard')),\n",
    "                    ('Robust', FE.RobustScaler_DF(prefix='Robust', quantile_range=(5.0, 95.0))),\n",
    "                    ('Quantile', FE.QuantileTransformer_DF(prefix='Quantile', n_quantiles=100, random_state=0)),\n",
    "                    ('Binary', FE.Binarizer_DF(prefix='Binary', threshold=0)),\n",
    "                    ('MinMax', FE.MinMaxScaler_DF(prefix='MinMax', feature_range=(0, 1))),\n",
    "                    ('MaxAbs', FE.MaxAbsScaler_DF(prefix='MaxAbs')),\n",
    "                    ('Norm', FE.Normalizer_DF(prefix='Norm', norm='l1')),\n",
    "                    ('KBin', FE.KBinsDiscretizer_DF(prefix='KBin', n_bins=10, encode='ordinal')),\n",
    "                    ('Log1p', FE.Log1pTransformer(prefix='Log1p')),\n",
    "                    ('Sqrt', FE.SqrtTransformer(prefix='Sqrt')),\n",
    "                    ('Reciprocal', FE.ReciprocalTransformer(prefix='Reciprocal'))\n",
    "                    ])\n",
    "\n",
    "# Custom Transformers in Sequence for NUMERICAL Features\n",
    "NUM_Pipe          = Pipeline([\n",
    "                    ('Selector', FE.FeatureSelector_NUM()),\n",
    "                    ('FU_Pipe', Pipe_FU)\n",
    "                    ])\n",
    "\n",
    "\n",
    "# (2) fit()\n",
    "NUM_Pipe.fit(train_X, train_y)\n",
    "\n",
    "\n",
    "# (3) transform()\n",
    "train_X_FE = NUM_Pipe.transform(train_X)\n",
    "test_X_FE  = NUM_Pipe.transform(test_X)\n",
    "\n",
    "# Feature Dimension\n",
    "print('\\n' + '*'*50 + '\\nBefore vs After Feature Engineering (FE)\\n' + '*'*50)\n",
    "print('TRAIN: Before FE:' + str(train_X.shape))\n",
    "print('TRAIN: After FE: ' + str(train_X_FE.shape))\n",
    "print('TEST:  After FE: ' + str(test_X_FE.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Summary: TRAIN vs TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************************\n",
      "Correlation Summary: TRAIN vs TEST\n",
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAIN_Original</th>\n",
       "      <th>TRAIN_All</th>\n",
       "      <th>TEST_Original</th>\n",
       "      <th>TEST_All</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>416.000000</td>\n",
       "      <td>4759.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>4750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.001822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.008391</td>\n",
       "      <td>0.008241</td>\n",
       "      <td>0.009544</td>\n",
       "      <td>0.009769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.050927</td>\n",
       "      <td>-0.053020</td>\n",
       "      <td>-0.047839</td>\n",
       "      <td>-0.052411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1%</th>\n",
       "      <td>-0.021250</td>\n",
       "      <td>-0.021181</td>\n",
       "      <td>-0.017396</td>\n",
       "      <td>-0.018422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>-0.011900</td>\n",
       "      <td>-0.012161</td>\n",
       "      <td>-0.008281</td>\n",
       "      <td>-0.008881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>-0.008043</td>\n",
       "      <td>-0.008145</td>\n",
       "      <td>-0.005923</td>\n",
       "      <td>-0.006743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>-0.004580</td>\n",
       "      <td>-0.004556</td>\n",
       "      <td>-0.003767</td>\n",
       "      <td>-0.003983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30%</th>\n",
       "      <td>-0.002516</td>\n",
       "      <td>-0.002719</td>\n",
       "      <td>-0.002540</td>\n",
       "      <td>-0.002685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40%</th>\n",
       "      <td>-0.001268</td>\n",
       "      <td>-0.001387</td>\n",
       "      <td>-0.001394</td>\n",
       "      <td>-0.001374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000126</td>\n",
       "      <td>-0.000345</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>-0.000132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.001289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>0.002993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>0.004349</td>\n",
       "      <td>0.003975</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>0.005973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>0.010124</td>\n",
       "      <td>0.009791</td>\n",
       "      <td>0.015280</td>\n",
       "      <td>0.014301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>0.023199</td>\n",
       "      <td>0.023955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>0.024785</td>\n",
       "      <td>0.024489</td>\n",
       "      <td>0.031814</td>\n",
       "      <td>0.035375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.033124</td>\n",
       "      <td>0.048845</td>\n",
       "      <td>0.040092</td>\n",
       "      <td>0.044838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       TRAIN_Original    TRAIN_All  TEST_Original     TEST_All\n",
       "count      416.000000  4759.000000     415.000000  4750.000000\n",
       "mean         0.000401     0.000137       0.002034     0.001822\n",
       "std          0.008391     0.008241       0.009544     0.009769\n",
       "min         -0.050927    -0.053020      -0.047839    -0.052411\n",
       "1%          -0.021250    -0.021181      -0.017396    -0.018422\n",
       "5%          -0.011900    -0.012161      -0.008281    -0.008881\n",
       "10%         -0.008043    -0.008145      -0.005923    -0.006743\n",
       "20%         -0.004580    -0.004556      -0.003767    -0.003983\n",
       "30%         -0.002516    -0.002719      -0.002540    -0.002685\n",
       "40%         -0.001268    -0.001387      -0.001394    -0.001374\n",
       "50%         -0.000126    -0.000345      -0.000138    -0.000132\n",
       "60%          0.000982     0.000689       0.001142     0.001289\n",
       "70%          0.002454     0.002047       0.003062     0.002993\n",
       "80%          0.004349     0.003975       0.006202     0.005973\n",
       "90%          0.010124     0.009791       0.015280     0.014301\n",
       "95%          0.016400     0.015850       0.023199     0.023955\n",
       "99%          0.024785     0.024489       0.031814     0.035375\n",
       "max          0.033124     0.048845       0.040092     0.044838"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_list          = [.01, .05, .1, .2, .3, .4, .6, .7, .8, .9, .95, .99]\n",
    "flag_NUM        = train_X.select_dtypes(exclude=[object, 'category']).columns.tolist()\n",
    "corr_train      = train_X[flag_NUM].apply(lambda x: x.corr(train_y)).to_frame().describe(percentiles=p_list)\n",
    "corr_train_all  = train_X_FE.apply(lambda x: x.corr(train_y)).to_frame().describe(percentiles=p_list)\n",
    "\n",
    "corr_test       = test_X[flag_NUM].apply(lambda x: x.corr(test_y)).to_frame().describe(percentiles=p_list)\n",
    "corr_test_all   = test_X_FE.apply(lambda x: x.corr(test_y)).to_frame().describe(percentiles=p_list)\n",
    "\n",
    "corr_all         = pd.concat([corr_train, corr_train_all, corr_test, corr_test_all], axis=1)\n",
    "corr_all.columns = ['TRAIN_Original', 'TRAIN_All', 'TEST_Original', 'TEST_All']\n",
    "print('\\n' + '*'*50 + '\\nCorrelation Summary: TRAIN vs TEST\\n' + '*'*50)\n",
    "corr_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Transformed Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_FE_NUM = train_y.to_frame().\\\n",
    "                 merge(train_X_FE, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "df_test_FE_NUM  = test_y.to_frame().\\\n",
    "                  merge(test_X_FE, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "df_train_FE_NUM.to_pickle('data_new/Vol_df_train_FiosONT_FE_NUM_5months.pkl')\n",
    "df_test_FE_NUM.to_pickle('data_new/Vol_df_test_FiosONT_FE_NUM_5months.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
