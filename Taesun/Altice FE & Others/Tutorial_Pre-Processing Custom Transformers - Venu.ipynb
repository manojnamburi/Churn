{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Transformers for Pre-Processing\n",
    "**Custom Transformers** will conduct the following pre-processing:\n",
    "- [Missing values and imputation](#Missing-values-and-imputation)\n",
    "    - `Remove_MissingFeatures`\n",
    "        - Identify missing percentages of features.\n",
    "        - Remove features with missing % >= threshold missing %.\n",
    "        - **Note**: Be applied prior to **any missing value imputation**.\n",
    "- [Zero/near-zero variance features](#Zero/near-zero-variance-features)\n",
    "    - `Remove_ConstantFeatures`\n",
    "        - Identify features with a single unique value.\n",
    "        - Remove those constant features.\n",
    "- [Duplicate/highly correlated features](#Duplicate/highly-correlated-features)\n",
    "    - `Remove_CorrelatedFeatures`\n",
    "        - Compute pairwise correlation between features.\n",
    "        - Remove features with abs(correlation) >= threshold correlation.\n",
    "        - **Note**: Relevant to **numerical features only**.\n",
    "    - `Remove_DuplicateFeatures`\n",
    "        - Identify features with duplicate columns.\n",
    "        - Remove features with duplicate columns.\n",
    "- [Data Type Conversion](#Data-Type-Conversion)\n",
    "    - `Use_DefaultDataType`\n",
    "        - Identify features having data types inconsistent with default data types.\n",
    "        - Convert the data types into the default data types if inconsistent.\n",
    "        - **Note**: No feature removed!\n",
    "- [Default Imputation](#Default-Imputation)\n",
    "    - `Use_DefaultImputer`\n",
    "        - Use default imputation values.\n",
    "        - **Note**: No feature removed!        \n",
    "- Extreme values/outliers (**TBD if necessary**)\n",
    "    - How to define extreme values\n",
    "    - How to replace extreme values\n",
    "- Non-informative features (**TBD if necessary**)\n",
    "    - Identify non-informative features\n",
    "    - Decide which one be dropped        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Transformers: Parameters, Methods and Attributes\n",
    "### Parameters\n",
    "#### Common Parameters\n",
    "All Custom Transformers require a pandas dataframe (df) that consists of all features:\n",
    "- **X**: a df with all possible features\n",
    "    - e.g.: Remove_DuplicateFeatures().fit(X)\n",
    "\n",
    "#### Additional Parameters\n",
    "Custom Transformers may require additional parameters with respect to their purpose:\n",
    "- **Transformer specific parameter(s)** such as 'correlation_threshold'\n",
    "    - default:\n",
    "        - Remove_MissingFeatures(**missing_threshold=0.99**)\n",
    "        - Remove_ConstantFeatures(**unique_threshold=1**)\n",
    "        - Remove_CorrelatedFeatures(**correlation_threshold=0.90**)\n",
    "    - e.g.: Remove_CorrelatedFeatures(correlation_threshold=0.99).fit(X)        \n",
    "- **y**: a pandas series that represent a churn status: \n",
    "    - default = None\n",
    "    - e.g.: Remove_CorrelatedFeatures(correlation_threshold=0.99).fit(X, y)\n",
    "\n",
    "### Methods\n",
    "#### Common Methods\n",
    "All Custom Transformers have the same methods as **any other sklearn transformers**:\n",
    "- **fit**: CustomTransformer().fit()\n",
    "- **transform**: CustomTransformer().transform()\n",
    "- **fit_transform**: CustomTransformer().fit_transform()\n",
    "\n",
    "#### Additional Methods\n",
    "Some Custom Transformers have additional methods as below:\n",
    "- **plot**: CustomTransformer().plot() \n",
    "\n",
    "### Attributes\n",
    "#### Common Attributes\n",
    "All Custom Transformers have the below attributes:\n",
    "- **summary_dropped_**: CustomTransformer().fit().summary_dropped_\n",
    "    - a df that includes dropped features with ***simple*** summary statistics \n",
    "- **summary_dropped_NUM_**: CustomTransformer().fit().summary_dropped_NUM_\n",
    "    - a df that includes dropped **Numerical** features with ***full*** summary statistics \n",
    "- **summary_dropped_CAT_**: CustomTransformer().fit().summary_dropped_CAT_\n",
    "    - a df that includes dropped **Categorical** features with ***full*** summary statistics \n",
    "- **features_dropped_**: CustomTransformer().fit().features_dropped_\n",
    "    - a list of dropped features\n",
    "- **features_kept_**: CustomTransformer().fit().features_kept_\n",
    "    - a list of kept features\n",
    "\n",
    "#### Additional Attributes\n",
    "Some Custom Transformers have additional attributes as below:\n",
    "- **features_irrelevant (Class Attribute)**: CustomTransformer().features_irrelevant\n",
    "    - a list of irrelevant features that are pre-excluded before pre-processing\n",
    "- `Use_DefaultImputer` has the following attributes:\n",
    "    - **summary_imputation_**: Use_DefaultImputer.fit().summary_imputation_\n",
    "    - **summary_imputation_NUM_**: Use_DefaultImputer.fit().summary_imputation_NUM_\n",
    "    - **summary_imputation_CAT_**: Use_DefaultImputer.fit().summary_imputation_CAT_\n",
    "- `Use_DefaultDataType` has the following attributes:\n",
    "    - **summary_inconsistent_dtypes_**: Use_DefaultDataType.fit().summary_inconsistent_dtypes_\n",
    "    - **summary_inconsistent_NUM_**: Use_DefaultDataType.fit().summary_inconsistent_NUM_\n",
    "    - **summary_inconsistent_CAT_**: Use_DefaultDataType.fit().summary_inconsistent_CAT_\n",
    "    - **features_inconsistent_dtypes_**: Use_DefaultDataType.fit().features_inconsistent_dtypes_\n",
    "    - **features_inconsistent_NUM_**: Use_DefaultDataType.fit().features_inconsistent_NUM_\n",
    "    - **features_inconsistent_CAT_**: Use_DefaultDataType.fit().features_inconsistent_CAT_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things You Need to Do\n",
    "### Data: Your Own TRAIN/TEST\n",
    "- Create Your Own TRAIN/TEST datasets from a master churn data file.\n",
    "\n",
    "### Dictionary: Default Data Type and Imputation Values\n",
    "- Import default data type and imputation value dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 0. Import Required Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import Custom Transformers Here!!!\n",
    "import PreProcessing_Custom_Transformers_v2 as PP         ### Import PreProcessing Customer Transformers\n",
    "\n",
    "# Use the Updated Attribute/Imputation Dictionaries!!!\n",
    "%run 'data_new/attribute_dictionary.py'\n",
    "%run 'data_new/imputation_dictionary.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "TRAIN vs TEST Datasets\n",
      "**************************************************\n",
      "Competitive Area:  ['Fios ONT Competitive Area']\n",
      "The Shape of TRAIN Data: (126928, 1017)\n",
      "The Shape of TEST Data:  (123820, 1017)\n",
      "\n",
      "**************************************************\n",
      "Overall Churn Rate\n",
      "**************************************************\n",
      "TRAIN:  0.0199\n",
      "TEST:   0.0258 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_pickle('data_new/df_train_Fios ONT Competitive Area.pkl')\n",
    "df_test  = pd.read_pickle('data_new/df_test_Fios ONT Competitive Area.pkl')\n",
    "\n",
    "# Use '' as index\n",
    "df_train.set_index('chc_id', inplace=True)\n",
    "df_test.set_index('chc_id', inplace=True)\n",
    "\n",
    "# TRAIN\n",
    "train_X = df_train.drop('status', axis=1).copy()\n",
    "train_y = df_train['status']\n",
    "\n",
    "# TEST\n",
    "test_X  = df_test.drop('status', axis=1).copy()\n",
    "test_y  = df_test['status']\n",
    "\n",
    "# Sample Size\n",
    "print('*'*50 + '\\nTRAIN vs TEST Datasets\\n' + '*'*50)\n",
    "print('Competitive Area: ', df_train.competitive_area.unique())\n",
    "print('The Shape of TRAIN Data: ' + str(df_train.shape))\n",
    "print('The Shape of TEST Data:  ' + str(df_test.shape))\n",
    "\n",
    "## Churn Rate by Sample Type\n",
    "print('\\n' + '*'*50 + '\\nOverall Churn Rate\\n' + '*'*50)\n",
    "print('TRAIN: ', df_train.status.value_counts(normalize=True)[1].round(4))\n",
    "print('TEST:  ', df_test.status.value_counts(normalize=True)[1].round(4), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Pre-Processing: Use_DefaultDataType\n",
      "**************************************************\n",
      "- It will convert data types into default ones.\n",
      "\n",
      "**************************************************\n",
      "Pre-Processing: Remove_MissingFeatures\n",
      "**************************************************\n",
      "- It will remove features with a high missing pct.\n",
      "\n",
      "**************************************************\n",
      "Pre-Processing: Remove_ConstantFeatures\n",
      "**************************************************\n",
      "- It will remove features with 1 unique value(s).\n",
      "\n",
      "**************************************************\n",
      "Pre-Processing: Remove_CorrelatedFeatures\n",
      "**************************************************\n",
      "- It will work on Numerical Features Only, doing nothing on Categorical Features.\n",
      "\n",
      "- It may take 10+ minutes. Be patient!\n",
      "\n",
      "**************************************************\n",
      "Pre-Processing: Remove_DuplicateFeatures\n",
      "**************************************************\n",
      "- It may take 10+ minutes. Be patient!\n",
      "\n",
      "**************************************************\n",
      "Pre-Processing: Use_DefaultImputere\n",
      "**************************************************\n",
      "- It will append default imputation values to missings.\n",
      "\n",
      "**************************************************\n",
      "Pre-Processing: Remove_ConstantFeatures\n",
      "**************************************************\n",
      "- It will remove features with 1 unique value(s).\n",
      "\n",
      "**************************************************\n",
      "Pre-Processing: Remove_CorrelatedFeatures\n",
      "**************************************************\n",
      "- It will work on Numerical Features Only, doing nothing on Categorical Features.\n",
      "\n",
      "- It may take 10+ minutes. Be patient!\n",
      "\n",
      "26 features with greater than 99.0% missing values\n",
      "27 features with 1 or fewer unique value(s)\n",
      "44 features with abs(correlation ) > 0.99 with other features\n",
      "3 features with duplicate columns\n",
      "14 features with 1 or fewer unique value(s)\n",
      "132 features with abs(correlation ) > 0.9 with other features\n",
      "\n",
      "**************************************************\n",
      "Before vs After Transformation\n",
      "**************************************************\n",
      "TRAIN: Before Transformation:(126928, 1016)\n",
      "TRAIN: After Transformation: (126928, 755)\n",
      "TEST:  After Transformation: (123820, 755)\n",
      "CPU times: user 41min 56s, sys: 12min 58s, total: 54min 55s\n",
      "Wall time: 52min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# (1) Make a Pipeline and Instantiate\n",
    "PP_Pipe = Pipeline([\n",
    "                    ('DataType', PP.Use_DefaultDataType(default_dtypes=attribute_dict)),\n",
    "                    ('Missing', PP.Remove_MissingFeatures(missing_threshold=0.99)), \n",
    "                    ('Constant1', PP.Remove_ConstantFeatures(unique_threshold=1, missing_threshold=0.00)), \n",
    "                    ('Correlated1', PP.Remove_CorrelatedFeatures(correlation_threshold=0.99)), \n",
    "                    ('Duplicate', PP.Remove_DuplicateFeatures()),\n",
    "                    ('Imputer', PP.Use_DefaultImputer(default_imputers=attribute_imputer_dict, default_dtypes=attribute_dict)),\n",
    "                    ('Constant2', PP.Remove_ConstantFeatures(unique_threshold=1, missing_threshold=0.00)), \n",
    "                    ('Correlated2', PP.Remove_CorrelatedFeatures(correlation_threshold=0.90))\n",
    "                  ])\n",
    "\n",
    "# 'Constant2' is added to handle (1) unique value = 0 and (2) default imputation value = 0.\n",
    "# 'Correlated2' is added to further remove correlated features after impuation.\n",
    "\n",
    "\n",
    "# (2) fit()\n",
    "# default: y=None\n",
    "PP_Pipe.fit(train_X, train_y)\n",
    "\n",
    "\n",
    "# (3) transform()\n",
    "train_X_Preprocessed = PP_Pipe.transform(train_X)\n",
    "test_X_Preprocessed  = PP_Pipe.transform(test_X)\n",
    "\n",
    "# Feature Dimension\n",
    "print('\\n' + '*'*50 + '\\nBefore vs After Transformation\\n' + '*'*50)\n",
    "print('TRAIN: Before Transformation:' + str(train_X.shape))\n",
    "print('TRAIN: After Transformation: ' + str(train_X_Preprocessed.shape))\n",
    "print('TEST:  After Transformation: ' + str(test_X_Preprocessed.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Common Attributes, `CustomTransformer().fit().features_dropped_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************************************\n",
      "Features Dropped Due to High Missing Pct\n",
      "**************************************************\n",
      " ['ddp_recurring_m1', 'espanol_save_offer_lift_amount', 'espanol_save_offer_months_remaining', 'gf_mig', 'hbo_svod', 'mover', 'ooldown_m1', 'ooldown_m2', 'ooldown_m3', 'other_offer_lift_amount', 'other_offer_months_remaining', 'outage_m1', 'outage_ool_m1', 'outage_ov_m1', 'outage_vid_m1', 'portout_m1', 'portout_m2', 'portout_m3', 'portout_m4', 'premium_offer_lift_amount', 'premium_offer_months_remaining', 'tcs_m1', 'uversezip', 'viddown_m1', 'viddown_m2', 'viddown_m3']\n",
      "\n",
      "**************************************************\n",
      "Features Dropped Due to Constant Value before Imputation\n",
      "**************************************************\n",
      " ['commprod_ind', 'curr_addl_did_blocks', 'curr_sip_sessions', 'curr_tf_lines', 'fiosont', 'music_choice_m1', 'music_choice_m2', 'ool4b_flag', 'ov4b_flag', 'range_extend_m1', 'range_extend_m2', 'rewindbuf_chrg_m1', 'rewindbuf_chrg_m2', 'rsdvr_160free_m1', 'rsdvr_160free_m2', 'rsdvr_160pay_m1', 'rsdvr_160pay_m2', 'rsdvr_160promo_m1', 'rsdvr_160promo_m2', 'rsdvr_plus_pay_m1', 'static_ip_m1', 'static_ip_m2', 'tollfree_m1', 'tollfree_m2', 'trump', 'virtual_recep_m1', 'virtual_recep_m2']\n",
      "\n",
      "**************************************************\n",
      "Features Dropped Due to Multicollinearity before Imputation\n",
      "**************************************************\n",
      " ['acu_int_usage_calls_edp_m2', 'acu_wifi_usage_up_mb_m2', 'analog_m2', 'analog_m3', 'analog_m4', 'anarev_m3', 'anarev_m4', 'box_m2', 'box_m3', 'box_m4', 'emaildays_m2', 'ioequip_m2', 'ioequip_m4', 'mb_total_usage1', 'mb_total_usage2', 'mbreceived_m2', 'other_othrrev_m3', 'other_othrrev_m4', 'othrrev_m3', 'othrrev_m4', 'outage_ool_change_m1_m4', 'ovpromo_mthsleft_m1', 'ovpromo_mthsleft_m2', 'ovpromo_mthsleft_m3', 'ovpromo_mthsleft_m4', 'sa1850_m2', 'sa1850_m3', 'sa4200_m1', 'sa4200_m3', 'sa4250_m2', 'sa4250_m3', 'sa8300_dvr_m1', 'samsung_m2', 'samsung_m3', 'samsung_m4', 'sony_cc_m2', 'sports_sc_rev_m3', 'sports_sc_rev_m4', 'total_discos', 'totalsessions_m2', 'vidpromo_mthsleft_m1', 'vidpromo_mthsleft_m2', 'vidpromo_mthsleft_m3', 'vidpromo_mthsleft_m4']\n",
      "\n",
      "**************************************************\n",
      "Features Dropped Due to Duplicate Columns before Imputation\n",
      "**************************************************\n",
      " ['node', 'new_video_tier2', 'rsdvr_plus_pay_m2']\n",
      "\n",
      "**************************************************\n",
      "Features Dropped Due to Constant Value after Imputation\n",
      "**************************************************\n",
      " ['othercall_m1', 'othercall_m2', 'othercall_m3', 'othercall_m4', 'othercall_m5', 'othercall_m6', 'prgm_oneworldsports_m1', 'prgm_oneworldsports_m2', 'prgm_oneworldsports_m3', 'prgm_oneworldsports_m4', 'save_sale_m1', 'save_sale_m2', 'save_sale_m3', 'save_sale_m4']\n",
      "\n",
      "**************************************************\n",
      "Features Dropped Due to Multicollinearity after Imputation\n",
      "**************************************************\n",
      " ['acu_email_num_of_logins_m2', 'acu_ool_usage_down_mb_m2', 'anarev_m1', 'anarev_m2', 'avg_anarev_m1_m6', 'avg_baserev_m1_m6', 'avg_dvrrev_m1_m6', 'avg_oolrev_m1_m6', 'avg_other_othrrev_m1_m6', 'avg_othrrev_m1_m6', 'avg_ovrev_m1_m6', 'avg_revenue_m1_m6', 'avg_sports_sc_rev_m1_m6', 'avg_svodrev_m1_m6', 'baserev_m1', 'baserev_m2', 'baserev_m3', 'baserev_m4', 'baserev_m5', 'baserev_m6', 'bill_disp_m2', 'bill_m1', 'box_m1', 'boxswap_m2', 'boxswap_m3', 'chg_baserev_m4_m5', 'chg_revenue_m1_m2', 'chg_revenue_m2_m3', 'chg_revenue_m3_m4', 'chg_revenue_m5_m6', 'dvrrev_m1', 'dvrrev_m2', 'dvrrev_m3', 'emaildays_m4', 'emailtrans_m2', 'emailtrans_m3', 'ioequip_m1', 'ioequip_m3', 'iorev_m2', 'iorev_m3', 'iorev_m4', 'kom_cust_tenure_nbr', 'kom_tenure', 'manualsessions_m2', 'manualsessions_m4', 'max_anarev_m1_m6', 'max_baserev_m1_m6', 'max_dvrrev_m1_m6', 'max_other_othrrev_m1_m6', 'max_othrrev_m1_m6', 'max_ovrev_m1_m6', 'max_revenue_m1_m6', 'max_sports_sc_rev_m1_m6', 'mb_ool_usage1', 'mb_ool_usage2', 'mbreceived_m3', 'min_baserev_m1_m6', 'min_dvrrev_m1_m6', 'min_oolrev_m1_m6', 'min_other_othrrev_m1_m6', 'min_ovrev_m1_m6', 'min_svodrev_m1_m6', 'ool_ov_voice_offer_months_remaining', 'oolpromo_mthsleft_m2', 'oolpromo_mthsleft_m3', 'oolpromo_mthsleft_m4', 'oolrev_m1', 'oolrev_m2', 'oolrev_m3', 'oolrev_m4', 'other_othrrev_m1', 'other_othrrev_m2', 'other_othrrev_m5', 'other_othrrev_m6', 'othrrev_m1', 'othrrev_m2', 'outage_m3', 'outage_m4', 'outage_ool_m2', 'outage_ool_m3', 'outage_ov_m2', 'outage_vid_change_m1_m4', 'outage_vid_m1_m4', 'outage_vid_m2', 'outage_vid_m4', 'ovrev_m2', 'ovrev_m3', 'ovrev_m4', 'period_chg_anarev_m1_m6', 'period_chg_baserev_m1_m6', 'period_chg_oolrev_m1_m6', 'period_chg_othrrev_m1_m6', 'period_chg_ovrev_m1_m6', 'period_chg_revenue_m1_m6', 'revenue_m1', 'revenue_m2', 'revenue_m3', 'revenue_m4', 'revenue_m5', 'revenue_m6', 'sa1850_m1', 'sa4200_m2', 'sa4250_m1', 'sa8300_dvr_m2', 'sa8300_dvr_m4', 'samsung_m1', 'save_m3', 'save_m4', 'sessiontimemin_m3', 'sessiontimemin_m4', 'sony_cc_m3', 'sony_cc_m4', 'sports_sc_rev_m1', 'sports_sc_rev_m2', 'svodrev_m1', 'svodrev_m2', 'svodrev_m3', 'times_repeated', 'totalcontact_m1', 'totalcontact_m2', 'totalsessions_m3', 'totalsessions_m4', 'ttl_chg_dvrrev_m1_m6', 'ttl_chg_other_othrrev_m1_m6', 'ttl_chg_revenue_m1_m6', 'ttl_chg_svodrev_m1_m6', 'ttl_internet_usage_in_gb_m0', 'ttl_internet_usage_in_gb_m6', 'ttl_rev_abs_change_3m', 'ttl_rev_abs_change_6m', 'ttl_streaming_usage_in_gb_m2', 'ttl_streaming_usage_in_gb_m6']\n"
     ]
    }
   ],
   "source": [
    "print('\\n' + '*'*50 + '\\nFeatures Dropped Due to High Missing Pct\\n' + '*'*50 + '\\n', \n",
    "      PP_Pipe.named_steps['Missing'].features_dropped_)\n",
    "\n",
    "print('\\n' + '*'*50 + '\\nFeatures Dropped Due to Constant Value before Imputation\\n' + '*'*50 + '\\n', \n",
    "      PP_Pipe.named_steps['Constant1'].features_dropped_)\n",
    "\n",
    "print('\\n' + '*'*50 + '\\nFeatures Dropped Due to Multicollinearity before Imputation\\n' + '*'*50 + '\\n', \n",
    "      PP_Pipe.named_steps['Correlated1'].features_dropped_)\n",
    "\n",
    "print('\\n' + '*'*50 + '\\nFeatures Dropped Due to Duplicate Columns before Imputation\\n' + '*'*50 + '\\n', \n",
    "      PP_Pipe.named_steps['Duplicate'].features_dropped_)\n",
    "\n",
    "print('\\n' + '*'*50 + '\\nFeatures Dropped Due to Constant Value after Imputation\\n' + '*'*50 + '\\n', \n",
    "      PP_Pipe.named_steps['Constant2'].features_dropped_)\n",
    "\n",
    "print('\\n' + '*'*50 + '\\nFeatures Dropped Due to Multicollinearity after Imputation\\n' + '*'*50 + '\\n', \n",
    "      PP_Pipe.named_steps['Correlated2'].features_dropped_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print/Retrieve Common Attributes, `CustomTransformer().fit().summary_dropped_` if necessary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
