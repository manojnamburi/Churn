{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process TRAIN/TEST Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. TRAIN/TEST Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.25 s, sys: 1.21 s, total: 2.46 s\n",
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### 0. Import Required Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "### Import Customer Transformers\n",
    "import PreProcessing_Custom_Transformers_v2 as PP\n",
    "import FeatureEngineering_Custom_Transformers as FE\n",
    "import FeatureCreation_Custom_Transformers as FC\n",
    "\n",
    "# Use the Updated Attribute/Imputation Dictionaries!!!\n",
    "%run 'data_new/attribute_dictionary.py'\n",
    "%run 'data_new/imputation_dictionary.py'\n",
    "\n",
    "# Remove DataConversionWarning\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Pre-Processing: Use_DefaultImputere\n",
      "**************************************************\n",
      "- It will append default imputation values to missings.\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Before vs After Transformation\n",
      "**************************************************\n",
      "TRAIN: Before Transformation:(687967, 1022)\n",
      "TRAIN: After Transformation: (687967, 1022)\n",
      "TEST:  After Transformation: (678079, 1022)\n",
      "(687967, 1023)\n",
      "(678079, 1023)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_train = pd.read_pickle('data_new/CLUSTER_df_train_Fios Competitive Area.pkl')\n",
    "df_test  = pd.read_pickle('data_new/CLUSTER_df_test_Fios Competitive Area.pkl')\n",
    "\n",
    "# Use 'chc_id' as index, and sort by index.\n",
    "df_train.set_index('chc_id', inplace=True)\n",
    "df_test.set_index('chc_id', inplace=True)\n",
    "\n",
    "df_train = df_train.sort_index()\n",
    "df_test  = df_test.sort_index()\n",
    "\n",
    "# TRAIN\n",
    "train_X = df_train.drop('status', axis=1).copy()\n",
    "train_y = df_train['status']\n",
    "\n",
    "# TEST\n",
    "test_X  = df_test.drop('status', axis=1).copy()\n",
    "test_y  = df_test['status']\n",
    "\n",
    "del df_train, df_test\n",
    "\n",
    "\n",
    "\n",
    "### Pre-Processing\n",
    "# (1) Make a Pipeline and Instantiate\n",
    "Pipe_PP = PP.Use_DefaultImputer(default_imputers=attribute_imputer_dict, default_dtypes=attribute_dict)\n",
    "\n",
    "\n",
    "# (2) fit()\n",
    "Pipe_PP.fit(train_X, train_y)\n",
    "\n",
    "\n",
    "# (3) transform()\n",
    "train_X_PP = Pipe_PP.transform(train_X)\n",
    "test_X_PP  = Pipe_PP.transform(test_X)\n",
    "\n",
    "# Feature Dimension\n",
    "print('\\n' + '*'*50 + '\\nBefore vs After Transformation\\n' + '*'*50)\n",
    "print('TRAIN: Before Transformation:' + str(train_X.shape))\n",
    "print('TRAIN: After Transformation: ' + str(train_X_PP.shape))\n",
    "print('TEST:  After Transformation: ' + str(test_X_PP.shape))\n",
    "\n",
    "# Create Datasets that Consist of Pre-processed and New Features.\n",
    "df_train_PP = train_y.to_frame().\\\n",
    "              merge(train_X_PP, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "df_test_PP  = test_y.to_frame().\\\n",
    "              merge(test_X_PP, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# Save Data for Feature Engineering\n",
    "# Pre-processed data with new features\n",
    "df_train_PP.to_pickle('data_new/CLUSTER_df_train_Fios_PP.pkl')\n",
    "df_test_PP.to_pickle('data_new/CLUSTER_df_test_Fios_PP.pkl')\n",
    "\n",
    "print(df_train_PP.shape)\n",
    "print(df_test_PP.shape)\n",
    "\n",
    "del df_train_PP, df_test_PP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fios ONT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Pre-Processing: Use_DefaultImputere\n",
      "**************************************************\n",
      "- It will append default imputation values to missings.\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Before vs After Transformation\n",
      "**************************************************\n",
      "TRAIN: Before Transformation:(178486, 1022)\n",
      "TRAIN: After Transformation: (178486, 1022)\n",
      "TEST:  After Transformation: (185586, 1022)\n",
      "(178486, 1023)\n",
      "(185586, 1023)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_train = pd.read_pickle('data_new/CLUSTER_df_train_Fios ONT Competitive Area.pkl')\n",
    "df_test  = pd.read_pickle('data_new/CLUSTER_df_test_Fios ONT Competitive Area.pkl')\n",
    "\n",
    "# Use 'chc_id' as index, and sort by index.\n",
    "df_train.set_index('chc_id', inplace=True)\n",
    "df_test.set_index('chc_id', inplace=True)\n",
    "\n",
    "df_train = df_train.sort_index()\n",
    "df_test  = df_test.sort_index()\n",
    "\n",
    "# TRAIN\n",
    "train_X = df_train.drop('status', axis=1).copy()\n",
    "train_y = df_train['status']\n",
    "\n",
    "# TEST\n",
    "test_X  = df_test.drop('status', axis=1).copy()\n",
    "test_y  = df_test['status']\n",
    "\n",
    "del df_train, df_test\n",
    "\n",
    "\n",
    "\n",
    "### Pre-Processing\n",
    "# (1) Make a Pipeline and Instantiate\n",
    "Pipe_PP = PP.Use_DefaultImputer(default_imputers=attribute_imputer_dict, default_dtypes=attribute_dict)\n",
    "\n",
    "\n",
    "# (2) fit()\n",
    "Pipe_PP.fit(train_X, train_y)\n",
    "\n",
    "\n",
    "# (3) transform()\n",
    "train_X_PP = Pipe_PP.transform(train_X)\n",
    "test_X_PP  = Pipe_PP.transform(test_X)\n",
    "\n",
    "# Feature Dimension\n",
    "print('\\n' + '*'*50 + '\\nBefore vs After Transformation\\n' + '*'*50)\n",
    "print('TRAIN: Before Transformation:' + str(train_X.shape))\n",
    "print('TRAIN: After Transformation: ' + str(train_X_PP.shape))\n",
    "print('TEST:  After Transformation: ' + str(test_X_PP.shape))\n",
    "\n",
    "# Create Datasets that Consist of Pre-processed and New Features.\n",
    "df_train_PP = train_y.to_frame().\\\n",
    "              merge(train_X_PP, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "df_test_PP  = test_y.to_frame().\\\n",
    "              merge(test_X_PP, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# Save Data for Feature Engineering\n",
    "# Pre-processed data with new features\n",
    "df_train_PP.to_pickle('data_new/CLUSTER_df_train_FiosONT_PP.pkl')\n",
    "df_test_PP.to_pickle('data_new/CLUSTER_df_test_FiosONT_PP.pkl')\n",
    "\n",
    "print(df_train_PP.shape)\n",
    "print(df_test_PP.shape)\n",
    "\n",
    "del df_train_PP, df_test_PP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Fios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Pre-Processing: Use_DefaultImputere\n",
      "**************************************************\n",
      "- It will append default imputation values to missings.\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Before vs After Transformation\n",
      "**************************************************\n",
      "TRAIN: Before Transformation:(182762, 1022)\n",
      "TRAIN: After Transformation: (182762, 1022)\n",
      "TEST:  After Transformation: (180628, 1022)\n",
      "(182762, 1023)\n",
      "(180628, 1023)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_train = pd.read_pickle('data_new/CLUSTER_df_train_Pre-Fios Competitive Area.pkl')\n",
    "df_test  = pd.read_pickle('data_new/CLUSTER_df_test_Pre-Fios Competitive Area.pkl')\n",
    "\n",
    "# Use 'chc_id' as index, and sort by index.\n",
    "df_train.set_index('chc_id', inplace=True)\n",
    "df_test.set_index('chc_id', inplace=True)\n",
    "\n",
    "df_train = df_train.sort_index()\n",
    "df_test  = df_test.sort_index()\n",
    "\n",
    "# TRAIN\n",
    "train_X = df_train.drop('status', axis=1).copy()\n",
    "train_y = df_train['status']\n",
    "\n",
    "# TEST\n",
    "test_X  = df_test.drop('status', axis=1).copy()\n",
    "test_y  = df_test['status']\n",
    "\n",
    "del df_train, df_test\n",
    "\n",
    "\n",
    "\n",
    "### Pre-Processing\n",
    "# (1) Make a Pipeline and Instantiate\n",
    "Pipe_PP = PP.Use_DefaultImputer(default_imputers=attribute_imputer_dict, default_dtypes=attribute_dict)\n",
    "\n",
    "\n",
    "# (2) fit()\n",
    "Pipe_PP.fit(train_X, train_y)\n",
    "\n",
    "\n",
    "# (3) transform()\n",
    "train_X_PP = Pipe_PP.transform(train_X)\n",
    "test_X_PP  = Pipe_PP.transform(test_X)\n",
    "\n",
    "# Feature Dimension\n",
    "print('\\n' + '*'*50 + '\\nBefore vs After Transformation\\n' + '*'*50)\n",
    "print('TRAIN: Before Transformation:' + str(train_X.shape))\n",
    "print('TRAIN: After Transformation: ' + str(train_X_PP.shape))\n",
    "print('TEST:  After Transformation: ' + str(test_X_PP.shape))\n",
    "\n",
    "# Create Datasets that Consist of Pre-processed and New Features.\n",
    "df_train_PP = train_y.to_frame().\\\n",
    "              merge(train_X_PP, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "df_test_PP  = test_y.to_frame().\\\n",
    "              merge(test_X_PP, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# Save Data for Feature Engineering\n",
    "# Pre-processed data with new features\n",
    "df_train_PP.to_pickle('data_new/CLUSTER_df_train_PreFios_PP.pkl')\n",
    "df_test_PP.to_pickle('data_new/CLUSTER_df_test_PreFios_PP.pkl')\n",
    "\n",
    "print(df_train_PP.shape)\n",
    "print(df_test_PP.shape)\n",
    "\n",
    "del df_train_PP, df_test_PP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Competitive Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Pre-Processing: Use_DefaultImputere\n",
      "**************************************************\n",
      "- It will append default imputation values to missings.\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Before vs After Transformation\n",
      "**************************************************\n",
      "TRAIN: Before Transformation:(477817, 1022)\n",
      "TRAIN: After Transformation: (477817, 1022)\n",
      "TEST:  After Transformation: (477088, 1022)\n",
      "(477817, 1023)\n",
      "(477088, 1023)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_train = pd.read_pickle('data_new/CLUSTER_df_train_Non-Competitive Area.pkl')\n",
    "df_test  = pd.read_pickle('data_new/CLUSTER_df_test_Non-Competitive Area.pkl')\n",
    "\n",
    "# Use 'chc_id' as index, and sort by index.\n",
    "df_train.set_index('chc_id', inplace=True)\n",
    "df_test.set_index('chc_id', inplace=True)\n",
    "\n",
    "df_train = df_train.sort_index()\n",
    "df_test  = df_test.sort_index()\n",
    "\n",
    "# TRAIN\n",
    "train_X = df_train.drop('status', axis=1).copy()\n",
    "train_y = df_train['status']\n",
    "\n",
    "# TEST\n",
    "test_X  = df_test.drop('status', axis=1).copy()\n",
    "test_y  = df_test['status']\n",
    "\n",
    "del df_train, df_test\n",
    "\n",
    "\n",
    "\n",
    "### Pre-Processing\n",
    "# (1) Make a Pipeline and Instantiate\n",
    "Pipe_PP = PP.Use_DefaultImputer(default_imputers=attribute_imputer_dict, default_dtypes=attribute_dict)\n",
    "\n",
    "\n",
    "# (2) fit()\n",
    "Pipe_PP.fit(train_X, train_y)\n",
    "\n",
    "\n",
    "# (3) transform()\n",
    "train_X_PP = Pipe_PP.transform(train_X)\n",
    "test_X_PP  = Pipe_PP.transform(test_X)\n",
    "\n",
    "# Feature Dimension\n",
    "print('\\n' + '*'*50 + '\\nBefore vs After Transformation\\n' + '*'*50)\n",
    "print('TRAIN: Before Transformation:' + str(train_X.shape))\n",
    "print('TRAIN: After Transformation: ' + str(train_X_PP.shape))\n",
    "print('TEST:  After Transformation: ' + str(test_X_PP.shape))\n",
    "\n",
    "# Create Datasets that Consist of Pre-processed and New Features.\n",
    "df_train_PP = train_y.to_frame().\\\n",
    "              merge(train_X_PP, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "df_test_PP  = test_y.to_frame().\\\n",
    "              merge(test_X_PP, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# Save Data for Feature Engineering\n",
    "# Pre-processed data with new features\n",
    "df_train_PP.to_pickle('data_new/CLUSTER_df_train_Non_PP.pkl')\n",
    "df_test_PP.to_pickle('data_new/CLUSTER_df_test_Non_PP.pkl')\n",
    "\n",
    "print(df_train_PP.shape)\n",
    "print(df_test_PP.shape)\n",
    "\n",
    "del df_train_PP, df_test_PP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-verse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Pre-Processing: Use_DefaultImputere\n",
      "**************************************************\n",
      "- It will append default imputation values to missings.\n",
      "\n",
      "\n",
      "**************************************************\n",
      "Before vs After Transformation\n",
      "**************************************************\n",
      "TRAIN: Before Transformation:(135316, 1022)\n",
      "TRAIN: After Transformation: (135316, 1022)\n",
      "TEST:  After Transformation: (134823, 1022)\n",
      "(135316, 1023)\n",
      "(134823, 1023)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_train = pd.read_pickle('data_new/CLUSTER_df_train_U-verse Competitive Area.pkl')\n",
    "df_test  = pd.read_pickle('data_new/CLUSTER_df_test_U-verse Competitive Area.pkl')\n",
    "\n",
    "# Use 'chc_id' as index, and sort by index.\n",
    "df_train.set_index('chc_id', inplace=True)\n",
    "df_test.set_index('chc_id', inplace=True)\n",
    "\n",
    "df_train = df_train.sort_index()\n",
    "df_test  = df_test.sort_index()\n",
    "\n",
    "# TRAIN\n",
    "train_X = df_train.drop('status', axis=1).copy()\n",
    "train_y = df_train['status']\n",
    "\n",
    "# TEST\n",
    "test_X  = df_test.drop('status', axis=1).copy()\n",
    "test_y  = df_test['status']\n",
    "\n",
    "del df_train, df_test\n",
    "\n",
    "\n",
    "\n",
    "### Pre-Processing\n",
    "# (1) Make a Pipeline and Instantiate\n",
    "Pipe_PP = PP.Use_DefaultImputer(default_imputers=attribute_imputer_dict, default_dtypes=attribute_dict)\n",
    "\n",
    "\n",
    "# (2) fit()\n",
    "Pipe_PP.fit(train_X, train_y)\n",
    "\n",
    "\n",
    "# (3) transform()\n",
    "train_X_PP = Pipe_PP.transform(train_X)\n",
    "test_X_PP  = Pipe_PP.transform(test_X)\n",
    "\n",
    "# Feature Dimension\n",
    "print('\\n' + '*'*50 + '\\nBefore vs After Transformation\\n' + '*'*50)\n",
    "print('TRAIN: Before Transformation:' + str(train_X.shape))\n",
    "print('TRAIN: After Transformation: ' + str(train_X_PP.shape))\n",
    "print('TEST:  After Transformation: ' + str(test_X_PP.shape))\n",
    "\n",
    "# Create Datasets that Consist of Pre-processed and New Features.\n",
    "df_train_PP = train_y.to_frame().\\\n",
    "              merge(train_X_PP, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "df_test_PP  = test_y.to_frame().\\\n",
    "              merge(test_X_PP, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "# Save Data for Feature Engineering\n",
    "# Pre-processed data with new features\n",
    "df_train_PP.to_pickle('data_new/CLUSTER_df_train_Uverse_PP.pkl')\n",
    "df_test_PP.to_pickle('data_new/CLUSTER_df_test_Uverse_PP.pkl')\n",
    "\n",
    "print(df_train_PP.shape)\n",
    "print(df_test_PP.shape)\n",
    "\n",
    "del df_train_PP, df_test_PP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
