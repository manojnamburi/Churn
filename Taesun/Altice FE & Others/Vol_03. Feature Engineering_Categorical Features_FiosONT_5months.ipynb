{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engineer Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Custom Transformers for Categorical Features\n",
    "**Feature Creation** consists of the following custom transformers:\n",
    "- `FeatureMaker`\n",
    "    - Create new features that can be used as grouping variables\n",
    "- `FeatureInteractionTransformer`\n",
    "    - Account for interaction between any pair of given features.\n",
    "    - Use newly created interaction features in further analyses\n",
    "- `FeatureAggregator`\n",
    "    - Aggregate both Numerical and Categorical features by a grouping variable.\n",
    "    - Use aggregated features as new features. \n",
    "- `RareCategoryEncoder`\n",
    "    - Re-group rare categories into either 'all_other' or most common category.\n",
    "    - Create more representative/manageable number of categories.\n",
    "- `UniversalCategoryEncoder`\n",
    "    - Encode CATEGORICAL features with selected encoding methods.\n",
    "    - Eocoding methods:\n",
    "        - `ohe`: Generate 0/1 binary variable for every label of CATEGORICAL features.\n",
    "        - `pct`: Replace category with its corresponding %.\n",
    "        - `count`: Replace category with its corresponding count.\n",
    "        - `ordinal`: Replace category with its order of average value of target y.\n",
    "        - `y_mean`: Replace category with its corresponding average value of target y.\n",
    "        - `y_log_ratio`: Replace category with its corresponding log(p(Churner)/p(Non-Churner)).\n",
    "        - `y_ratio`: Replace category with its corresponding (p(Churner)/p(Non-Churner)).\n",
    "\n",
    "- **Note**: \n",
    "    - Data will have ***'pandas dataframe'*** format before/after transformation.\n",
    "\n",
    "- References: \n",
    "    - sklearn Preprocessing: https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "    - sklear Pipeline: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "    - Featuretools: https://docs.featuretools.com/#\n",
    "    - Feature Engine: https://pypi.org/project/feature-engine/\n",
    "    - Category Encoders: http://contrib.scikit-learn.org/categorical-encoding/    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-Processed TRAIN/TEST Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Base Modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "### Import Customer Transformers\n",
    "import PreProcessing_Custom_Transformers_v2 as PP\n",
    "import FeatureEngineering_Custom_Transformers as FE\n",
    "import FeatureCreation_Custom_Transformers as FC\n",
    "\n",
    "# Remove DataConversionWarning\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "# from sklearn.exceptions import DataConversionWarning\n",
    "# warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: `FeatureMaker` is used at pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "TRAIN vs TEST Datasets\n",
      "**************************************************\n",
      "The Shape of TRAIN Data: (102451, 777)\n",
      "The Shape of TEST Data:  (100858, 777)\n",
      "\n",
      "**************************************************\n",
      "Overall Churn Rate\n",
      "**************************************************\n",
      "TRAIN:  0.0367\n",
      "TEST:   0.0405 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use Pre-Processed Data as TRAIN and TEST\n",
    "df_train = pd.read_pickle('data_new/Vol_df_train_FiosONT_PP_5months.pkl')\n",
    "df_test  = pd.read_pickle('data_new/Vol_df_test_FiosONT_PP_5months.pkl')\n",
    "\n",
    "# TRAIN\n",
    "train_X = df_train.drop('status', axis=1).copy()\n",
    "train_y = df_train['status']\n",
    "\n",
    "# TEST\n",
    "test_X  = df_test.drop('status', axis=1).copy()\n",
    "test_y  = df_test['status']\n",
    "\n",
    "# Sample Size\n",
    "print('*'*50 + '\\nTRAIN vs TEST Datasets\\n' + '*'*50)\n",
    "# print('Competitive Area: ', df_train.competitive_area.unique())\n",
    "print('The Shape of TRAIN Data: ' + str(df_train.shape))\n",
    "print('The Shape of TEST Data:  ' + str(df_test.shape))\n",
    "\n",
    "## Churn Rate by Sample Type\n",
    "print('\\n' + '*'*50 + '\\nOverall Churn Rate\\n' + '*'*50)\n",
    "print('TRAIN: ', df_train.status.value_counts(normalize=True)[1].round(4))\n",
    "print('TEST:  ', df_test.status.value_counts(normalize=True)[1].round(4), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/Use a Meta Custom Transfomer for Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ordinal' encoding requires target y.\n",
      "'y_mean' encoding requires target y.\n",
      "'y_log_ratio' encoding requires target y.\n",
      "'y_ratio' encoding requires target y.\n",
      "'FeatureAggregator' requires target y.\n",
      "\n",
      "**************************************************\n",
      "Before vs After Feature Engineering (FE)\n",
      "**************************************************\n",
      "TRAIN: Before FE:(102451, 776)\n",
      "TRAIN: After FE: (102451, 6891)\n",
      "TEST:  After FE: (100858, 6891)\n",
      "CPU times: user 1h 15min 19s, sys: 20min 29s, total: 1h 35min 49s\n",
      "Wall time: 1h 8min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# (1) Make a Pipeline in Parallel/Sequence and Instantiate \n",
    "# List of Features Used as Parameters\n",
    "fe_1st           = ['grp_tenure_3m', 'grp_payment_method', \\\n",
    "                    'grp_payment_25dollar', 'grp_payment_change_10dollar', 'grp_payment_change_5pct', \\\n",
    "                    'grp_payment_income', 'grp_call_csc', 'grp_call_bill', \\\n",
    "                    'grp_call_csr', 'grp_call_tsr']\n",
    "fe_2nd           = fe_1st + ['income_demos', 'ethnic', 'age_demos', 'archetype']\n",
    "fe_group         = ['census', 'cleansed_city', 'cleansed_zipcode']\n",
    "\n",
    "# Custom Transformers in Parallel for CATEGORICAL Features\n",
    "Pipe_FU          =  FE.FeatureUnion_DF([\n",
    "                    ('OHE', FC.UniversalCategoryEncoder(encoding_method='ohe')),\n",
    "                    ('PCT', FC.UniversalCategoryEncoder(encoding_method='pct', prefix='PCT')),\n",
    "                    ('COUNT', FC.UniversalCategoryEncoder(encoding_method='count', prefix='COUNT')),\n",
    "                    ('ORDINAL', FC.UniversalCategoryEncoder(encoding_method='ordinal', prefix='ORDINAL')),\n",
    "                    ('Y_MEAN', FC.UniversalCategoryEncoder(encoding_method='y_mean', prefix='Y_MEAN')),\n",
    "                    ('Y_LOG_RATIO', FC.UniversalCategoryEncoder(encoding_method='y_log_ratio', prefix='Y_LOG_RATIO')),\n",
    "                    ('Y_RATIO', FC.UniversalCategoryEncoder(encoding_method='y_ratio', prefix='Y_RATIO')),\n",
    "                    ('Aggregation', FC.FeatureAggregator(features_grouping=fe_group, correlation_threshold=0.01))\n",
    "                    ])\n",
    "\n",
    "# Custom Transformers in Sequence for CATEGORICAL Features\n",
    "CAT_Pipe          = Pipeline([\n",
    "                    ('Interaction', FC.FeatureInteractionTransformer(features_1st=fe_1st, features_2nd=fe_2nd)),\n",
    "                    ('RareCategory', FC.RareCategoryEncoder(category_min_pct=0.05, category_max_count=30)),\n",
    "                    ('FU_Pipe', Pipe_FU)\n",
    "                    ])\n",
    "\n",
    "# (2) fit()\n",
    "CAT_Pipe.fit(train_X, train_y)\n",
    "\n",
    "\n",
    "# (3) transform()\n",
    "train_X_FE = CAT_Pipe.transform(train_X)\n",
    "test_X_FE  = CAT_Pipe.transform(test_X)\n",
    "\n",
    "# Feature Dimension\n",
    "print('\\n' + '*'*50 + '\\nBefore vs After Feature Engineering (FE)\\n' + '*'*50)\n",
    "print('TRAIN: Before FE:' + str(train_X.shape))\n",
    "print('TRAIN: After FE: ' + str(train_X_FE.shape))\n",
    "print('TEST:  After FE: ' + str(test_X_FE.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Summary: TRAIN vs TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********************************************************************\n",
      "Correlation Summary: TRAIN vs TEST\n",
      "**********************************************************************\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAIN_All</th>\n",
       "      <th>TEST_All</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6813.000000</td>\n",
       "      <td>6743.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.004970</td>\n",
       "      <td>0.003665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.014884</td>\n",
       "      <td>0.013955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.048018</td>\n",
       "      <td>-0.054007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1%</th>\n",
       "      <td>-0.027277</td>\n",
       "      <td>-0.027083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>-0.012891</td>\n",
       "      <td>-0.013984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>-0.009446</td>\n",
       "      <td>-0.008889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>-0.004493</td>\n",
       "      <td>-0.004550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30%</th>\n",
       "      <td>-0.001772</td>\n",
       "      <td>-0.002533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40%</th>\n",
       "      <td>0.000505</td>\n",
       "      <td>-0.000472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.001273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.003372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>0.008042</td>\n",
       "      <td>0.005851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>0.012186</td>\n",
       "      <td>0.010674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>0.024537</td>\n",
       "      <td>0.021675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>0.033607</td>\n",
       "      <td>0.030887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>0.058461</td>\n",
       "      <td>0.051951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.069784</td>\n",
       "      <td>0.060759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TRAIN_All     TEST_All\n",
       "count  6813.000000  6743.000000\n",
       "mean      0.004970     0.003665\n",
       "std       0.014884     0.013955\n",
       "min      -0.048018    -0.054007\n",
       "1%       -0.027277    -0.027083\n",
       "5%       -0.012891    -0.013984\n",
       "10%      -0.009446    -0.008889\n",
       "20%      -0.004493    -0.004550\n",
       "30%      -0.001772    -0.002533\n",
       "40%       0.000505    -0.000472\n",
       "50%       0.002083     0.001273\n",
       "60%       0.004056     0.003372\n",
       "70%       0.008042     0.005851\n",
       "80%       0.012186     0.010674\n",
       "90%       0.024537     0.021675\n",
       "95%       0.033607     0.030887\n",
       "99%       0.058461     0.051951\n",
       "max       0.069784     0.060759"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_list          = [.01, .05, .1, .2, .3, .4, .6, .7, .8, .9, .95, .99]\n",
    "corr_train_all  = train_X_FE.apply(lambda x: x.corr(train_y)).to_frame().describe(percentiles=p_list)\n",
    "corr_test_all   = test_X_FE.apply(lambda x: x.corr(test_y)).to_frame().describe(percentiles=p_list)\n",
    "\n",
    "corr_all         = pd.concat([corr_train_all, corr_test_all], axis=1)\n",
    "corr_all.columns = ['TRAIN_All', 'TEST_All']\n",
    "print('\\n' + '*'*70 + '\\nCorrelation Summary: TRAIN vs TEST\\n' + '*'*70)\n",
    "corr_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Transformed Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_FE_CAT = train_y.to_frame().\\\n",
    "                  merge(train_X_FE, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "df_test_FE_CAT  = test_y.to_frame().\\\n",
    "                  merge(test_X_FE, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "df_train_FE_CAT.to_pickle('data_new/Vol_df_train_FiosONT_FE_CAT_5months.pkl')\n",
    "df_test_FE_CAT.to_pickle('data_new/Vol_df_test_FiosONT_FE_CAT_5months.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
